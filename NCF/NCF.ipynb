{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.19.0\n",
      "Pandas version: 2.2.3\n",
      "Numpy version: 2.0.2\n"
     ]
    }
   ],
   "source": [
    "print(f'Tensorflow version: {tf.__version__}')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'Numpy version: {np.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('../json/reviews_Kindle_Store_5.json', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df[['reviewerID', 'asin', 'overall', 'unixReviewTime']]\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "user_enc = LabelEncoder()\n",
    "item_enc = LabelEncoder()\n",
    "\n",
    "clean_df = pd.DataFrame()\n",
    "\n",
    "df['user'] = user_enc.fit_transform(df['reviewerID'])\n",
    "df['item'] = item_enc.fit_transform(df['asin'])\n",
    "df['rating'] = df['overall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7773</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61894</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53977</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8128</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50527</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982614</th>\n",
       "      <td>35142</td>\n",
       "      <td>61933</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982615</th>\n",
       "      <td>4097</td>\n",
       "      <td>61933</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982616</th>\n",
       "      <td>18464</td>\n",
       "      <td>61933</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982617</th>\n",
       "      <td>5981</td>\n",
       "      <td>61933</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982618</th>\n",
       "      <td>29928</td>\n",
       "      <td>61933</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>925471 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user   item  rating\n",
       "0        7773      0     5.0\n",
       "1       61894      0     4.0\n",
       "2       53977      0     4.0\n",
       "3        8128      0     5.0\n",
       "4       50527      0     4.0\n",
       "...       ...    ...     ...\n",
       "982614  35142  61933     5.0\n",
       "982615   4097  61933     5.0\n",
       "982616  18464  61933     5.0\n",
       "982617   5981  61933     5.0\n",
       "982618  29928  61933     5.0\n",
       "\n",
       "[925471 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = df[['user', 'item', 'rating']][df['rating'] >= 3.0]\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        # Make sure user and item IDs are within bounds\n",
    "        assert df['user'].max() < 68223, \"User ID out of bounds\"\n",
    "        assert df['item'].max() < 61934, \"Item ID out of bounds\"\n",
    "        \n",
    "        self.users = torch.tensor(df['user'].values, dtype=torch.long)\n",
    "        self.items = torch.tensor(df['item'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(df['rating'].values, dtype=torch.float).view(-1, 1)\n",
    "        # Normalize ratings for BCE loss\n",
    "        self.ratings = (self.ratings - 1) / 4.0  # Assuming ratings are 1-5\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dimension = 8, mlp_layers=[16,8]):\n",
    "        \"\"\" \n",
    "        num_users: number of users\n",
    "        num_items: number of items\n",
    "        embedding_dimension: dimension of the embeddings for the matrix factorization\n",
    "        mlp_layers: sizes of hidden mulit-layer-perceptron\n",
    "        \"\"\"\n",
    "        super(NCF, self).__init__()\n",
    "\n",
    "        #Matrix factorization embeddings\n",
    "        self.user_embeddings_mf = nn.Embedding(num_users, embedding_dimension)\n",
    "        self.item_embeddings_mf = nn.Embedding(num_items, embedding_dimension)\n",
    "\n",
    "        #multi-layer perceptron embeddings\n",
    "        self.user_embeddings_mlp = nn.Embedding(num_users, embedding_dimension)\n",
    "        self.item_embeddings_mlp = nn.Embedding(num_items, embedding_dimension)\n",
    "\n",
    "        # Initialize embeddings (optional, but good practice)\n",
    "        nn.init.normal_(self.user_embeddings_mf.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embeddings_mf.weight, std=0.01)\n",
    "        nn.init.normal_(self.user_embeddings_mlp.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embeddings_mlp.weight, std=0.01)\n",
    "\n",
    "        #MLP layers\n",
    "        mlp_modules = []\n",
    "        input_size = embedding_dimension * 2\n",
    "        for layer_size in mlp_layers:\n",
    "            mlp_modules.append(nn.Linear(input_size, layer_size))\n",
    "            mlp_modules.append(nn.ReLU())\n",
    "            input_size = layer_size\n",
    "        \n",
    "        self.mlp = nn.Sequential(*mlp_modules)\n",
    "\n",
    "        predict_size = embedding_dimension + mlp_layers[-1]\n",
    "        \n",
    "        # Final prediction layer -> output single score\n",
    "        self.final_layer = nn.Linear(predict_size, 1)\n",
    "\n",
    "        # You can use a Sigmoid at the end if doing binary classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        user_ids: [batch_size]\n",
    "        item_ids: [batch_size]\n",
    "        returns: predicted score [batch_size, 1]\n",
    "        \"\"\"\n",
    "        # 1) GMF part\n",
    "        user_gmf = self.user_embeddings_mf(user_ids)        # [batch_size, embedding_dim]\n",
    "        item_gmf = self.item_embeddings_mf(item_ids)        # [batch_size, embedding_dim]\n",
    "        gmf_output = user_gmf * item_gmf                    # element-wise product [batch_size, embedding_dim]\n",
    "\n",
    "        # 2) MLP part\n",
    "        user_mlp = self.user_embeddings_mlp(user_ids)        # [batch_size, embedding_dim]\n",
    "        item_mlp = self.item_embeddings_mlp(item_ids)        # [batch_size, embedding_dim]\n",
    "        mlp_input = torch.cat((user_mlp, item_mlp), dim=1)  # [batch_size, embedding_dim*2]\n",
    "        mlp_output = self.mlp(mlp_input)                    # [batch_size, mlp_layers[-1]]\n",
    "\n",
    "        # 3) Concatenate GMF & MLP\n",
    "        concat = torch.cat((gmf_output, mlp_output), dim=1) # [batch_size, embedding_dim + mlp_layers[-1]]\n",
    "\n",
    "        # 4) Final layer\n",
    "        logits = self.final_layer(concat)    # [batch_size, 1]\n",
    "        preds = self.sigmoid(logits)         # apply sigmoid for probability\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_split(df):\n",
    "    # Sort by user and (optionally) timestamp or item if available\n",
    "    df = df.sort_values(by=[\"user\", \"item\"])  # if no timestamp\n",
    "\n",
    "    test_rows = []\n",
    "    train_rows = []\n",
    "\n",
    "    # Leave the last interaction (or any 1) per user for test set\n",
    "    for user, group in df.groupby(\"user\"):\n",
    "        test_rows.append(group.iloc[-1])      # Last rating to test\n",
    "        train_rows.append(group.iloc[:-1])    # All others to train\n",
    "\n",
    "    test_df = pd.DataFrame(test_rows)\n",
    "    train_df = pd.concat(train_rows)\n",
    "\n",
    "    return train_df.reset_index(drop=True), test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.3446\n",
      "Epoch 2/5, Loss: 0.3088\n",
      "Epoch 3/5, Loss: 0.2840\n",
      "Epoch 4/5, Loss: 0.2688\n",
      "Epoch 5/5, Loss: 0.2602\n"
     ]
    }
   ],
   "source": [
    "train, test = leave_one_out_split(clean_df)\n",
    "\n",
    "train_dataset = RatingDataset(train)\n",
    "test_dataset = RatingDataset(test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Sample hyperparameters\n",
    "num_users = clean_df['user'].max() + 1  # +1 because 0-indexed\n",
    "num_items = clean_df['item'].max() + 1  # +1 because 0-indexed\n",
    "embedding_dimension = 8\n",
    "\n",
    "model = NCF(num_users, num_items, embedding_dimension=embedding_dimension, mlp_layers=[16, 8])\n",
    "model.train()  # set to training mode\n",
    "\n",
    "criterion = nn.BCELoss()  # for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for batch_users, batch_items, batch_ratings in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch_users, batch_items)\n",
    "        loss = criterion(predictions, batch_ratings)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch_users.size(0)  # Weighted by batch size\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3602\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    for batch_users, batch_items, batch_ratings in test_loader:\n",
    "        predictions = model(batch_users, batch_items)\n",
    "        test_loss += criterion(predictions, batch_ratings).item() * batch_users.size(0)\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_dataset)\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
